{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computing the Maximum Lyapunov Exponent via displacement\n",
    "\n",
    "We compare the MLE for standard training and robust training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Juptyer magic: For export. Makes the plots size right for the screen \n",
    "%matplotlib inline\n",
    "# %config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "%config InlineBackend.figure_formats = ['svg'] \n",
    "\n",
    "\n",
    "torch.backends.cudnn.deterministic = True\n",
    "seed = np.random.randint(1,200)\n",
    "seed = 59\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "print(seed)\n",
    "g = torch.Generator()\n",
    "g.manual_seed(seed)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_entropy = False #this leads to squared loss in the training\n",
    "data_noise = 0.4\n",
    "batch_size = 5000\n",
    "plotlim = [-3, 3]\n",
    "subfolder = 'blobs'\n",
    "#generated a picture as a test\n",
    "\n",
    "\n",
    "if cross_entropy == True:\n",
    "    label = 'scalar'\n",
    "else: label = 'vector'\n",
    "\n",
    "\n",
    "from models.training import create_dataloader\n",
    "dataloader, dataloader_viz = create_dataloader('blobs', noise = data_noise, batch_size = batch_size, plotlim = plotlim, random_state = seed, label = label)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model dynamics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import of the model dynamics that describe the neural ODE\n",
    "#The dynamics are based on the torchdiffeq package, that implements ODE solvers in the pytorch setting\n",
    "from models.neural_odes import NeuralODE, NeuralODEvar\n",
    "\n",
    "#for neural ODE based networks the network width is constant. In this example the input is 2 dimensional\n",
    "hidden_dim, data_dim = 2, 2 \n",
    "augment_dim = 0\n",
    "\n",
    "#T is the end time of the neural ODE evolution, num_steps are the amount of discretization steps for the ODE solver\n",
    "T, num_steps = 10, 50 #!!!\n",
    "step_size = T/num_steps\n",
    "param_layers = 2\n",
    "bound = 0.\n",
    "fp = False #this recent change made things not work anymore\n",
    "turnpike = False\n",
    "\n",
    "non_linearity = 'tanh' #'relu' #\n",
    "architecture = 'outside' #outside\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and generating level sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "num_epochs = 20 #number of optimization runs in which the dataset is used for gradient decent\n",
    "\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "anode = NeuralODEvar(device, data_dim, hidden_dim, augment_dim=augment_dim, non_linearity=non_linearity, \n",
    "                    architecture=architecture, T=T, time_steps=num_steps, num_params = param_layers, fixed_projector=fp, cross_entropy=cross_entropy)\n",
    "\n",
    "# anode = NeuralODE(device, data_dim, hidden_dim, augment_dim=augment_dim, non_linearity=non_linearity, \n",
    "#                     architecture=architecture, T=T, time_steps=num_steps, fixed_projector=fp, cross_entropy=cross_entropy)\n",
    "\n",
    "optimizer_anode = torch.optim.Adam(anode.parameters(), lr=1e-3) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.training import doublebackTrainer\n",
    "\n",
    "trainer_anode = doublebackTrainer(anode, optimizer_anode, device, cross_entropy=cross_entropy, turnpike = turnpike,\n",
    "                         bound=bound, fixed_projector=fp, verbose = True, eps_comp = 0.2) \n",
    "trainer_anode.train(dataloader, num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from plots.plots import classification_levelsets\n",
    "classification_levelsets(anode)\n",
    "plt.plot(trainer_anode.histories['epoch_loss_history'])\n",
    "plt.xlim(0, len(trainer_anode.histories['epoch_loss_history']) - 1)\n",
    "plt.ylim(0)\n",
    "plt.xlabel('Iterations')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#check that right hand side is autonomous\n",
    "input1 = torch.tensor([1, 0], dtype=torch.float32)\n",
    "times = torch.linspace(0,T,30)\n",
    "times = times[:-1]\n",
    "\n",
    "param_step = 10/1\n",
    "for t in times:\n",
    "   k = int(t/param_step)\n",
    "   print('output', anode.flow.dynamics(t,input1),t)\n",
    "   print(k)\n",
    "   print('dynamics weight:', anode.flow.dynamics.fc2_time[k].weight)\n",
    "   print('right hand-side', anode.flow.dynamics.forward(t, input1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from plots.gifs import trajectory_gif\n",
    "from IPython.display import Image\n",
    "\n",
    "#the function trajectory_gif creates the evolution trajectories of the input data through the network\n",
    "#the passing time corresponds to the depth of the network\n",
    "\n",
    "for X_viz, y_viz in dataloader_viz:\n",
    "    trajectory_gif(anode, X_viz[0:50], y_viz[0:50], timesteps=num_steps, filename = 'trajectory.gif', axlim = 8, dpi = 100)\n",
    "    break\n",
    "\n",
    "#Display of the generated gif\n",
    "traj = Image(filename=\"trajectory.gif\")\n",
    "display(traj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(torch.arange(0.,2 + 0.01,0.2))\n",
    "print(torch.arange(1.,2 + 0.2,0.2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.interpolate import interp1d\n",
    "\n",
    "def plot_trajectory(model, inputs, targets, stepsize, time_interval = None, dpi=200, alpha=0.9,\n",
    "                    alpha_line=0.9, x_lim = [-2,2], y_lim = [-2,2]):\n",
    "    from matplotlib import rc\n",
    "    rc(\"text\", usetex=False)\n",
    "    font = {'size': 18}\n",
    "    rc('font', **font)\n",
    "\n",
    "    # Define color based on targets\n",
    "\n",
    "    color = ['C1' if targets[i,1] > 0.0 else 'C0' for i in range(len(targets))]\n",
    "        \n",
    "    \n",
    "    \n",
    "    if time_interval is None:\n",
    "        time_interval = torch.tensor([0, model.T],dtype=torch.float32)\n",
    "        \n",
    "    start_time = time_interval[0].item()\n",
    "    end_time = time_interval[1].item()\n",
    "    num_steps_interval = int((end_time - start_time) / stepsize)\n",
    "    # print('amount steps', num_steps_interval)\n",
    "    integration_time = torch.arange(start_time, end_time + stepsize/100, stepsize) #using end_time + stepsize gave a weird inconsistency between including and excluding the step_size\n",
    "    # print(integration_time)\n",
    "    trajectories = model.flow(inputs, integration_time).detach() #output is of dimension [time_steps, number of inputs, dimension per input]\n",
    "\n",
    "    \n",
    "    for i in range(inputs.shape[0]):\n",
    "        plt.plot(trajectories[:,i, 0], trajectories[:,i, 1], linestyle='-', marker='', color = color[i], alpha = alpha_line, linewidth = 0.5)\n",
    "        \n",
    "    \n",
    "    x_min, x_max = x_lim[0], x_lim[1]\n",
    "    y_min, y_max = y_lim[0], y_lim[1]\n",
    "    plt.xlim(x_min, x_max)\n",
    "    plt.ylim(y_min, y_max)\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "    # plt.show()\n",
    "\n",
    "# Example usage\n",
    "# model, inputs, targets, timesteps should be defined before calling this function\n",
    "step_size = T/num_steps \n",
    "\n",
    "for begin_T in torch.arange(0,2):\n",
    "    interval = torch.tensor([begin_T, 3], dtype=torch.float32)\n",
    "    print(interval)\n",
    "    plot_trajectory(anode, X_viz[0:50], y_viz[0:50],stepsize = step_size, time_interval=interval, x_lim=[-5,5], y_lim = [-5,5])\n",
    "    plt.show()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_interval = torch.tensor([7.2, 10], dtype=torch.float32)\n",
    "stepsize = T/num_steps\n",
    "print(interval)\n",
    "\n",
    "start_time = time_interval[0].item()\n",
    "end_time = time_interval[1].item()\n",
    "num_steps_interval = int((end_time - start_time) / stepsize)\n",
    "integration_time = torch.arange(start_time, end_time + stepsize/100, stepsize) #using end_time + stepsize gave a weird inconsistency between\n",
    "\n",
    "# for t in times:\n",
    "#    k = int(t/param_step)\n",
    "#    print('output', anode.flow.dynamics(t,input1),t)\n",
    "#    print(k)\n",
    "#    print('dynamics weight:', anode.flow.dynamics.fc2_time[k].weight)\n",
    "#    print('right hand-side', anode.flow.dynamics.forward(t, input1))\n",
    "\n",
    "plot_trajectory(anode, X_viz[0:50], y_viz[0:50],stepsize = stepsize, time_interval=time_interval)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from plots.plots import classification_levelsets\n",
    "import os\n",
    "\n",
    "if not os.path.exists(subfolder):\n",
    "        os.makedirs(subfolder)\n",
    "        \n",
    "footnote = f'{num_epochs = }, {num_steps = }, {data_noise = }'\n",
    "        \n",
    "fig_name_base = os.path.join(subfolder, 'levelsets')\n",
    "classification_levelsets(anode, fig_name_base, footnote = footnote + ', eps = 0')\n",
    "from IPython.display import Image\n",
    "img1 = Image(filename = fig_name_base + '.png', width = 400)\n",
    "\n",
    "display(img1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lyapunov exponent computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define inputs\n",
    "input1 = torch.tensor([1, 0], dtype=torch.float32)\n",
    "input2 = torch.tensor([0, 1], dtype=torch.float32)\n",
    "time_interval = torch.tensor([0, T], dtype=torch.float32)\n",
    "\n",
    "\n",
    "def input_to_output(input, node, time_interval = torch.tensor([0, T], dtype=torch.float32)):\n",
    "    return node.flow(input, time_interval)[-1]\n",
    "\n",
    "def LEs(input, node, time_interval = torch.tensor([0, T], dtype=torch.float32)):\n",
    "    #fix the node so it is just a input to output of the other variable\n",
    "    input_to_output_lambda = lambda input: input_to_output(input, node, time_interval)\n",
    "    # Compute the Jacobian matrix\n",
    "    J = torch.autograd.functional.jacobian(input_to_output_lambda, input)\n",
    "    \n",
    "    # Perform Singular Value Decomposition\n",
    "    U, S, V = torch.svd(J)\n",
    "    \n",
    "    # Return the maximum singular value\n",
    "    return 1/(time_interval[1]-time_interval[0]) * np.log(S)\n",
    "\n",
    "# def LEs(singular_values,T):\n",
    "#     return 1/T * np.log(singular_values)\n",
    "    \n",
    "\n",
    "def input_to_output_elena(input):\n",
    "    return anode.flow.dynamics.forward(T-1,input)\n",
    "\n",
    "\n",
    "les = LEs(input1, anode)\n",
    "print(les)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot ANODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LE_grid(node, x_amount = 100, time_interval = torch.tensor([0, T], dtype=torch.float32)):\n",
    "        \n",
    "        x = torch.linspace(-2,2,x_amount)\n",
    "        y = torch.linspace(-2,2,x_amount)\n",
    "        X, Y = torch.meshgrid(x, y)\n",
    "\n",
    "        inputs = torch.stack([X,Y], dim=-1)\n",
    "        inputs = inputs.view(-1,2) #to be able to loop through all the grid values\n",
    "        inputs_MLE_max = torch.zeros(x_amount * x_amount)\n",
    "        inputs_MLE_min = torch.zeros(x_amount * x_amount)\n",
    "\n",
    "\n",
    "\n",
    "        for i, input in enumerate(inputs):\n",
    "                \n",
    "                inputs_MLE_max[i] = torch.max(LEs(input, node, time_interval))\n",
    "                inputs_MLE_min[i] = torch.min(LEs(input, node, time_interval))\n",
    "        \n",
    "        \n",
    "        output_max = inputs_MLE_max.view(x_amount,x_amount)\n",
    "        output_min = inputs_MLE_min.view(x_amount,x_amount)\n",
    "        \n",
    "        return output_max, output_min\n",
    "\n",
    "output_max, output_min = LE_grid(anode,x_amount = 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#testing grid plots\n",
    "ax_lim = 2\n",
    "stepsize = T/50\n",
    "interval = torch.tensor([0., T], dtype=torch.float32)\n",
    "\n",
    "traj_amount = 15\n",
    "x = torch.linspace(-2,2,traj_amount)\n",
    "y = torch.linspace(-2,2,traj_amount)\n",
    "X, Y = torch.meshgrid(x, y)\n",
    "\n",
    "inputs_grid = torch.stack([X,Y], dim=-1)\n",
    "inputs_grid = inputs_grid.view(-1,2) #to be able to loop through all the grid values\n",
    "\n",
    "print(f'{inputs_grid.shape = }')\n",
    "labels_grid = torch.zeros(traj_amount**2,2)\n",
    "print(inputs_grid.shape[0])\n",
    "print(labels_grid.shape[0])\n",
    "\n",
    "plot_trajectory(anode, inputs_grid, labels_grid,stepsize = stepsize, time_interval=interval, alpha = 0.5)\n",
    "# plot_trajectory(anode, X_viz[0:40], y_viz[0:40],stepsize = stepsize, time_interval=interval)\n",
    "anodeimg_max = plt.imshow(np.rot90(output_max), origin='upper', extent=(-ax_lim, ax_lim, -ax_lim, ax_lim),cmap = 'viridis')\n",
    "vmin_max, vmax_max = anodeimg_max.get_clim()\n",
    "\n",
    "plt.colorbar()  # Show color scale\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from matplotlib.colors import CenteredNorm, to_rgba, LinearSegmentedColormap\n",
    "\n",
    "anodeimg_max = plt.imshow(np.rot90(output_max), origin='upper', extent=(-2, 2, -2, 2),cmap = 'viridis')\n",
    "vmin_max, vmax_max = anodeimg_max.get_clim()\n",
    "\n",
    "plt.colorbar()  # Show color scale\n",
    "plt.savefig('MLE_max.png',bbox_inches='tight', dpi=300, format='png', facecolor = 'white')\n",
    "plt.close()\n",
    "\n",
    "anodeimg_min = plt.imshow(np.rot90(output_min), origin='upper', extent=(-2, 2, -2, 2),cmap = 'viridis')#, norm=CenteredNorm(vcenter=0)) # cmap='viridis')\n",
    "vmin_min, vmax_min = anodeimg_min.get_clim()\n",
    "\n",
    "plt.colorbar()  # Show color scale\n",
    "plt.savefig('MLE_min.png',bbox_inches='tight', dpi=300, format='png', facecolor = 'white')\n",
    "plt.close()\n",
    "\n",
    "img1 = Image(filename = fig_name_base + '.png', width = 400)\n",
    "img2 = Image(filename = 'MLE_max.png', width = 400)\n",
    "img3 = Image(filename = 'MLE_min.png', width = 400)\n",
    "\n",
    "display(img1,img2,img3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evolution of the Finite Time Lyapunov Exponents over the whole interval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imageio\n",
    "import os\n",
    "\n",
    "# Directory to save images\n",
    "image_dir = 'gif_images'\n",
    "if not os.path.exists(image_dir):\n",
    "    os.makedirs(image_dir)\n",
    "\n",
    "\n",
    "x_amount = 80\n",
    "# Generate and save plots\n",
    "\n",
    "T= 10\n",
    "interval_length = 5\n",
    "t_values_step = 5\n",
    "t_values = np.arange(0, T-interval_length + 5, 5)\n",
    "print(t_values)\n",
    "for t in t_values:\n",
    "    time_interval = torch.tensor([0, interval_length], dtype=torch.float32) + t\n",
    "    \n",
    "    output_max, output_min = LE_grid(anode, x_amount, time_interval)\n",
    "    \n",
    "    # Create a figure with 2 subplots side by side\n",
    "    fig, axs = plt.subplots(1, 2, figsize=(10, 5))\n",
    "    \n",
    "    # Plot output_min on the first subplot\n",
    "    im1 = axs[0].imshow(np.rot90(output_max), origin='upper', extent=(-2, 2, -2, 2), cmap='viridis')\n",
    "    # im1.set_clim(vmin=vmin_max, vmax=vmax_max)\n",
    "    fig.colorbar(im1, ax=axs[0], orientation='vertical')  # Show color scale\n",
    "    axs[0].set_title(f'finite time LE (max) for interval = {time_interval}', fontsize=7)\n",
    "    plt.sca(axs[0])\n",
    "    plot_trajectory(anode, inputs_grid, labels_grid,stepsize = step_size, time_interval=time_interval)\n",
    "    \n",
    "    # Plot output_max on the second subplot\n",
    "    im2 = axs[1].imshow(np.rot90(output_min), origin='upper', extent=(-2, 2, -2, 2), cmap='viridis')\n",
    "    fig.colorbar(im2, ax=axs[1], orientation='vertical')  # Show color scale\n",
    "    axs[1].set_title(f'finite time LE (min) for interval = {time_interval}', fontsize=7)\n",
    "    # im2.set_clim(vmin_min,vmax_min)\n",
    "    \n",
    "    \n",
    "    # Adjust layout to prevent overlap\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    filename = os.path.join(image_dir, f'plot_{t:.1f}.png')\n",
    "    plt.savefig(filename, bbox_inches='tight', dpi=100, format='png', facecolor='white')\n",
    "    plt.close()\n",
    "\n",
    "# Create GIF\n",
    "images = []\n",
    "for t in t_values:\n",
    "    filename = os.path.join(image_dir, f'plot_{t:.1f}.png')\n",
    "    images.append(imageio.imread(filename))\n",
    "\n",
    "imageio.mimsave('finite_time_LE_test.gif', images, fps=1)\n",
    "\n",
    "# Clean up (optional)\n",
    "for t in t_values:\n",
    "    os.remove(os.path.join(image_dir, f'plot_{t:.1f}.png'))\n",
    "os.rmdir(image_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "LEevo_test = Image(filename=\"finite_time_LE_per_param_subint.gif\")\n",
    "display(LEevo_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "in the autonomous case any interval of same length should give the same LE. So the above gif makes sense!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imageio\n",
    "import os\n",
    "\n",
    "# Directory to save images\n",
    "image_dir = 'gif_images'\n",
    "if not os.path.exists(image_dir):\n",
    "    os.makedirs(image_dir)\n",
    "\n",
    "T = 10\n",
    "param_layers = 10\n",
    "x_amount = 30\n",
    "# Generate and save plots\n",
    "time_step = 0.2 #T/num_steps\n",
    "t_values = np.arange(1, T-time_step, time_step)\n",
    "for t in t_values:\n",
    "    time_interval = torch.tensor([t, T], dtype=torch.float32)\n",
    "    print(time_interval)\n",
    "    output_max, output_min = LE_grid(anode, x_amount, time_interval)\n",
    "    \n",
    "    # Create a figure with 2 subplots side by side\n",
    "    fig, axs = plt.subplots(1, 2, figsize=(10, 5))\n",
    "    \n",
    "    # Plot output_min on the first subplot\n",
    "    im1 = axs[0].imshow(np.rot90(output_max), origin='upper', extent=(-2, 2, -2, 2), cmap='viridis')\n",
    "    # im1.set_clim(vmin=vmin_max, vmax=vmax_max)\n",
    "    fig.colorbar(im1, ax=axs[0], orientation='vertical')  # Show color scale\n",
    "    axs[0].set_title(f'finite time LE (max) for interval = {time_interval}', fontsize=7)\n",
    "    plt.sca(axs[0])\n",
    "    plot_trajectory(anode, inputs_grid, labels_grid,stepsize = time_step, time_interval=time_interval)\n",
    "    \n",
    "    # Plot output_max on the second subplot\n",
    "    im2 = axs[1].imshow(np.rot90(output_min), origin='upper', extent=(-2, 2, -2, 2), cmap='viridis')\n",
    "    fig.colorbar(im2, ax=axs[1], orientation='vertical')  # Show color scale\n",
    "    axs[1].set_title(f'finite time LE (min) for interval = {time_interval}', fontsize=7)\n",
    "    # im2.set_clim(vmin_min,vmax_min)\n",
    "    \n",
    "    \n",
    "    # Adjust layout to prevent overlap\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    filename = os.path.join(image_dir, f'plot_{t:.1f}.png')\n",
    "    plt.savefig(filename, bbox_inches='tight', dpi=100, format='png', facecolor='white')\n",
    "    plt.close()\n",
    "\n",
    "# Create GIF\n",
    "images = []\n",
    "for t in t_values:\n",
    "    filename = os.path.join(image_dir, f'plot_{t:.1f}.png')\n",
    "    images.append(imageio.imread(filename))\n",
    "\n",
    "imageio.mimsave('finite_time_LE_test.gif', images, fps=1)\n",
    "\n",
    "# Clean up (optional)\n",
    "for t in t_values:\n",
    "    os.remove(os.path.join(image_dir, f'plot_{t:.1f}.png'))\n",
    "os.rmdir(image_dir)\n",
    "\n",
    "LEevo_test = Image(filename=\"finite_time_LE_test.gif\")\n",
    "display(LEevo_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imageio\n",
    "import os\n",
    "\n",
    "# Directory to save images\n",
    "image_dir = 'gif_images'\n",
    "if not os.path.exists(image_dir):\n",
    "    os.makedirs(image_dir)\n",
    "\n",
    "T = 10\n",
    "param_layers = 10\n",
    "dt = 1\n",
    "x_amount = 20\n",
    "# Generate and save plots\n",
    "time_step = 0.2\n",
    "t_values = np.arange(time_step, T-time_step, time_step)\n",
    "for t in t_values:\n",
    "    time_interval = torch.tensor([0, t], dtype=torch.float32)\n",
    "    \n",
    "    output_max, output_min = LE_grid(anode, x_amount, time_interval)\n",
    "    \n",
    "    # Create a figure with 2 subplots side by side\n",
    "    fig, axs = plt.subplots(1, 2, figsize=(10, 5))\n",
    "    \n",
    "    # Plot output_min on the first subplot\n",
    "    im1 = axs[0].imshow(np.rot90(output_max), origin='upper', extent=(-2, 2, -2, 2), cmap='viridis')\n",
    "    # im1.set_clim(vmin=vmin_max, vmax=vmax_max)\n",
    "    fig.colorbar(im1, ax=axs[0], orientation='vertical')  # Show color scale\n",
    "    axs[0].set_title(f'finite time LE (max) for interval = {time_interval}', fontsize=7)\n",
    "    \n",
    "    # Plot output_max on the second subplot\n",
    "    im2 = axs[1].imshow(np.rot90(output_min), origin='upper', extent=(-2, 2, -2, 2), cmap='viridis')\n",
    "    fig.colorbar(im2, ax=axs[1], orientation='vertical')  # Show color scale\n",
    "    axs[1].set_title(f'finite time LE (min) for interval = {time_interval}', fontsize=7)\n",
    "    # im2.set_clim(vmin_min,vmax_min)\n",
    "    \n",
    "    \n",
    "    # Adjust layout to prevent overlap\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    filename = os.path.join(image_dir, f'plot_{t:.1f}.png')\n",
    "    plt.savefig(filename, bbox_inches='tight', dpi=100, format='png', facecolor='white')\n",
    "    plt.close()\n",
    "\n",
    "# Create GIF\n",
    "images = []\n",
    "for t in t_values:\n",
    "    filename = os.path.join(image_dir, f'plot_{t:.1f}.png')\n",
    "    images.append(imageio.imread(filename))\n",
    "\n",
    "imageio.mimsave('finite_time_LE_test.gif', images, fps=1)\n",
    "\n",
    "# Clean up (optional)\n",
    "for t in t_values:\n",
    "    os.remove(os.path.join(image_dir, f'plot_{t:.1f}.png'))\n",
    "os.rmdir(image_dir)\n",
    "\n",
    "LEevo_test = Image(filename=\"finite_time_LE_test.gif\")\n",
    "display(LEevo_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "neuralODE",
   "language": "python",
   "name": "neuralode"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "vscode": {
   "interpreter": {
    "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
