{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import importlib\n",
    "\n",
    "# Juptyer magic: For export. Makes the plots size right for the screen \n",
    "%matplotlib inline\n",
    "# %config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "%config InlineBackend.figure_formats = ['svg'] \n",
    "\n",
    "\n",
    "torch.backends.cudnn.deterministic = True\n",
    "seed = np.random.randint(1,200)\n",
    "# seed = 60 #59\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "print(seed)\n",
    "g = torch.Generator()\n",
    "g.manual_seed(seed)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_entropy = False #this leads to squared loss in the training\n",
    "data_noise = 0.02\n",
    "num_points = 5000\n",
    "plotlim = [-3, 3]\n",
    "subfolder = 'make_dataloader_1dim' #all the files generated from this notebook get saved into this subfolder\n",
    "\n",
    "import os\n",
    "if not os.path.exists(subfolder):\n",
    "    os.makedirs(subfolder)\n",
    "\n",
    "\n",
    "label = 'scalar' #choose between 'scalar' and 'vector'. Scalar means that the labels are -1 and 1, vector means that the labels are (0, -2) and (0, 2)\n",
    "\n",
    "\n",
    "\n",
    "def create_dataloader(data_type, num_points = 3000, noise = 0.15, factor = 0.15, random_state = 1, shuffle = True, plotlim = [-2, 2], cross_entropy = False, label = 'scalar', ticks = True, markersize = 50, filename = 'trainingset'):\n",
    "    \n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from sklearn.datasets import make_moons, make_circles, make_blobs\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    import matplotlib.pyplot as plt\n",
    "    from torch.utils import data as data\n",
    "    from torch.utils.data import DataLoader, TensorDataset\n",
    "    \n",
    "    label_types = ['scalar', 'vector']\n",
    "    if label not in label_types:\n",
    "        raise ValueError(\"Invalid label type. Expected one of: %s\" % label_types)\n",
    "    \n",
    "    if data_type == 'circles':\n",
    "        X, y = make_circles(num_points, noise=noise, factor=factor, random_state=random_state, shuffle = shuffle)\n",
    "\n",
    "    elif data_type == 'blobs':\n",
    "        centers = [[-1, -1], [1, 1]]\n",
    "        X, y = make_blobs(\n",
    "    n_samples=num_points, centers=centers, cluster_std=noise, random_state=random_state)\n",
    "           \n",
    "    elif data_type == 'moons':\n",
    "        X, y = make_moons(num_points, noise = noise, shuffle = shuffle , random_state = random_state)\n",
    "    \n",
    "    elif data_type == 'xor':\n",
    "        X = torch.randint(low=0, high=2, size=(num_points, 2), dtype=torch.float32)\n",
    "        y = np.logical_xor(X[:, 0] > 0, X[:, 1] > 0).float()\n",
    "        # y = y.to(torch.int64)\n",
    "        X += noise * torch.randn(X.shape)\n",
    "        \n",
    "    else: \n",
    "        print('datatype not supported')\n",
    "        return None, None\n",
    "    \n",
    "    \n",
    "    #Split the data into training and test set\n",
    "    X = StandardScaler().fit_transform(X)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.2, random_state=random_state, shuffle = shuffle)\n",
    "    \n",
    "    # for plotting purposes\n",
    "    data_0 = X_train[y_train == 0]\n",
    "    data_1 = X_train[y_train == 1]\n",
    "    \n",
    "    plt.figure(figsize = (5,5), dpi = 100)\n",
    "    plt.scatter(data_1[:, 0], data_1[:, 1], edgecolor=\"#333\", alpha = 0.5, s = markersize)\n",
    "    plt.scatter(data_0[:, 0], data_0[:, 1], edgecolor=\"#333\",  alpha = 0.5, s = markersize)\n",
    "    plt.xlim(plotlim)\n",
    "    plt.ylim(plotlim)\n",
    "    ax = plt.gca()\n",
    "    ax.set_aspect('equal')\n",
    "    plt.xlabel(r'$x_1$', fontsize=12)\n",
    "    plt.ylabel(r'$x_2$', fontsize=12)\n",
    "    if ticks == False:\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "\n",
    "    plt.savefig(filename + '.png', bbox_inches='tight', dpi=300, format='png', facecolor = 'white')\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "    if label == 'vector':\n",
    "        y_train = np.array([(0., -2.) if label == 1 else (0., 2.) for label in y_train])\n",
    "        y_test = np.array([(0., -2.) if label == 1 else (0., 2.) for label in y_test])\n",
    "    \n",
    "    if label == 'scalar' and cross_entropy == False:\n",
    "        y_train = np.array([1. if label == 1 else -1. for label in y_train])[:,None]  # unsqueeze to make it a 2D tensor for MSE\n",
    "        y_test = np.array([1. if label == 1 else -1. for label in y_test])[:,None]  \n",
    "\n",
    "    g = torch.Generator()\n",
    "    g.manual_seed(random_state)\n",
    "    \n",
    "    # Convert to torch tensors\n",
    "    X_train = torch.Tensor(X_train) # transform to torch tensor for dataloader\n",
    "    y_train = torch.Tensor(y_train) #transform to torch tensor for dataloader\n",
    "\n",
    "    X_test = torch.Tensor(X_test) # transform to torch tensor for dataloader\n",
    "    y_test = torch.Tensor(y_test) #transform to torch tensor for dataloader\n",
    "\n",
    "    if cross_entropy == True:\n",
    "        X_train = X_train.type(torch.float32)  #type of orginial pickle.load data\n",
    "        y_train = y_train.type(torch.int64) #dtype of original picle.load data\n",
    "\n",
    "        X_test = X_test.type(torch.float32)  #type of orginial pickle.load data\n",
    "        y_test = y_test.type(torch.int64) #dtype of original picle.load data\n",
    "        \n",
    "    else:\n",
    "        X_train = X_train.type(torch.float32)  #type of orginial pickle.load data\n",
    "        y_train = y_train.type(torch.float32) #dtype of original picle.load data\n",
    "\n",
    "        X_test = X_test.type(torch.float32)  #type of orginial pickle.load data\n",
    "        y_test = y_test.type(torch.float32) #dtype of original picle.load data\n",
    "\n",
    "\n",
    "    train_data = TensorDataset(X_train,y_train) # create your datset\n",
    "    test_data = TensorDataset(X_test, y_test)\n",
    "\n",
    "    train = DataLoader(train_data, batch_size=64, shuffle=shuffle, generator=g)\n",
    "    test = DataLoader(test_data, batch_size=256, shuffle=shuffle, generator = g) #128 before\n",
    "\n",
    "\n",
    "    return train, test\n",
    "\n",
    "dataloader, dataloader_viz = create_dataloader('moons', noise = data_noise, num_points = num_points, plotlim = plotlim, random_state = seed, label = label, cross_entropy=cross_entropy, filename = subfolder + '/trainingset')\n",
    "\n",
    "for X, y in dataloader:\n",
    "    print(y)\n",
    "    break\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model dynamics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import of the model dynamics that describe the neural ODE\n",
    "#The dynamics are based on the torchdiffeq package, that implements ODE solvers in the pytorch setting\n",
    "from models.neural_odes import NeuralODEvar\n",
    "\n",
    "#for neural ODE based networks the network width is constant. In this example the input is 2 dimensional\n",
    "hidden_dim, data_dim = 2, 2 \n",
    "augment_dim = 0\n",
    "output_dim = 1\n",
    "\n",
    "#T is the end time of the neural ODE evolution, time_steps are the amount of discretization steps for the ODE solver\n",
    "T, time_steps = 10, 100 #\n",
    "step_size = T/time_steps\n",
    "num_params = 10 #the number of distinct parameters present in the interval. they are spread equidistant over the interval [0, T]. As there are 100 time_steps, the interval is divided into 10 parts, each of length 1 with 10 time_steps per subinterval.\n",
    "bound = 0.\n",
    "turnpike = False\n",
    "\n",
    "non_linearity = 'tanh' #'relu' #\n",
    "architecture = 'inside' #outside\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and generating level sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "num_epochs = 60 #number of optimization runs in which the dataset is used for gradient decent\n",
    "\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "anode = NeuralODEvar(device, data_dim, hidden_dim, output_dim = output_dim, augment_dim=augment_dim, non_linearity=non_linearity, \n",
    "                    architecture=architecture, T=T, time_steps=time_steps, num_params = num_params, cross_entropy=cross_entropy)\n",
    "\n",
    "\n",
    "optimizer_anode = torch.optim.Adam(anode.parameters(), lr=1e-3) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.training import doublebackTrainer\n",
    "\n",
    "trainer_anode = doublebackTrainer(anode, optimizer_anode, device, cross_entropy=cross_entropy, turnpike = turnpike,\n",
    "                         bound=bound, verbose = True) \n",
    "trainer_anode.train(dataloader, num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = torch.arange(0, 1, step=0.5)\n",
    "x2 = torch.arange(0, 1, step=0.5)\n",
    "xx1, xx2  = torch.meshgrid(x1, x2)  # Meshgrid function as in numpy should emulate indexing='xy'\n",
    "model_inputs = torch.stack([xx1, xx2], dim=-1)\n",
    "\n",
    "print(model_inputs)\n",
    "\n",
    "preds, _ = anode(model_inputs)\n",
    "\n",
    "print(preds.sigmoid().squeeze())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = torch.tensor([1., 0., 7])\n",
    "test[-1] = test[-1].sigmoid()\n",
    "test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plots.plots\n",
    "importlib.reload(plots.plots)\n",
    "from plots.plots import classification_levelsets\n",
    "classification_levelsets(anode)\n",
    "plt.plot(trainer_anode.histories['epoch_loss_history'])\n",
    "plt.xlim(0, len(trainer_anode.histories['epoch_loss_history']) - 1)\n",
    "plt.ylim(0)\n",
    "plt.xlabel('Iterations')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import plots.gifs\n",
    "importlib.reload(plots.gifs) # Reload the module to ensure the latest changes are applied\n",
    "from plots.gifs import trajectory_gif\n",
    "from IPython.display import Image\n",
    "\n",
    "#the function trajectory_gif creates the evolution trajectories of the input data through the network\n",
    "#the passing time corresponds to the depth of the network\n",
    "\n",
    "for X_viz, y_viz in dataloader_viz:\n",
    "    print(y_viz.shape)\n",
    "    trajectory_gif(anode, X_viz[0:50], y_viz[0:50], timesteps=time_steps, filename = subfolder + '/trajectory', axlim = 8, dpi = 100)\n",
    "    break\n",
    "\n",
    "#Display of the generated gif\n",
    "traj = Image(filename=subfolder + \"/trajectory.gif\")\n",
    "display(traj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(plots.plots)\n",
    "\n",
    "import os\n",
    "\n",
    "from plots.plots import plot_points_from_traj, input_to_traj_and_color, plot_vectorfield\n",
    "from plots.plots import create_gif_subintervals\n",
    "import imageio\n",
    "import io\n",
    "\n",
    "filename = subfolder + '/FTLE_per_param_fun_test'\n",
    "create_gif_subintervals(anode, le_density=2, filename=filename)\n",
    "LEevo_test = Image(filename=filename + \".gif\")\n",
    "display(LEevo_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "neuralODE",
   "language": "python",
   "name": "neuralode"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "vscode": {
   "interpreter": {
    "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
