{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Late robustness\n",
    "\n",
    "During the model training, we activate the robustness term only after the model expresses the basic topology of the data\n",
    "In the robustness phase the decision boundaries are then diffused and robustified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Juptyer magic: For export. Makes the plots size right for the screen \n",
    "%matplotlib inline\n",
    "# %config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "%config InlineBackend.figure_formats = ['svg'] \n",
    "\n",
    "\n",
    "torch.backends.cudnn.deterministic = True\n",
    "seed = np.random.randint(1,200)\n",
    "# seed = 56\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "print(seed)\n",
    "g = torch.Generator()\n",
    "g.manual_seed(seed)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_noise = 0.05\n",
    "data_noise = 0.15\n",
    "plotlim = [-3, 3]\n",
    "subfolder = 'xor'\n",
    "\n",
    "\n",
    "from models.training import create_dataloader\n",
    "dataloader, dataloader_viz = create_dataloader('xor', noise = data_noise, plotlim = plotlim, random_state = seed, label = 'vector')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x_batch, y_batch in dataloader:\n",
    "    print(x_batch, y_batch)\n",
    "    print(y_batch[0:20].size())\n",
    "    \n",
    "    print(len(y_batch.shape) > 1)\n",
    "    break"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model dynamics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import of the model dynamics that describe the neural ODE\n",
    "#The dynamics are based on the torchdiffeq package, that implements ODE solvers in the pytorch setting\n",
    "from models.neural_odes import NeuralODE, NeuralODE_justflow\n",
    "\n",
    "#for neural ODE based networks the network width is constant. In this example the input is 2 dimensional\n",
    "hidden_dim, data_dim = 2, 2 \n",
    "augment_dim = 0\n",
    "\n",
    "#T is the end time of the neural ODE evolution, num_steps are the amount of discretization steps for the ODE solver\n",
    "T, num_steps = 6, 6\n",
    "bound = 0.\n",
    "\n",
    "\n",
    "fp = False\n",
    "\n",
    "\n",
    "cross_entropy = False #this leads to squared loss in the training\n",
    "turnpike = False\n",
    "\n",
    "non_linearity = 'tanh'#'relu' # #\n",
    "architecture = 'inside' #outside\n",
    "layers = 2 #if i use some custom dynamics\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and generating level sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "activations = {'tanh': nn.Tanh(),\n",
    "                'relu': nn.ReLU(),\n",
    "                'sigmoid': nn.Sigmoid(),\n",
    "                'leakyrelu': nn.LeakyReLU(negative_slope=0.25, inplace=True)\n",
    "}\n",
    "architectures = {'inside': -1, 'outside': 0, 'bottleneck': 1}\n",
    "\n",
    "\n",
    "\"\"\"Define an autonomous ODE dynamic\"\"\"\n",
    "\n",
    "class Dynamics_autonomous(nn.Module):\n",
    "    \"\"\"\n",
    "    The nonlinear, right hand side $f(x(t)) of a neural ODE.\n",
    "    \"\"\"\n",
    "    def __init__(self, device, data_dim, hidden_dim, augment_dim=0, \n",
    "                non_linearity='tanh', architecture='inside', T=10, layers=10):\n",
    "        super(Dynamics_autonomous, self).__init__()\n",
    "        self.device = device\n",
    "        self.augment_dim = augment_dim\n",
    "        self.data_dim = data_dim\n",
    "        self.input_dim = data_dim + augment_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "\n",
    "        if non_linearity not in activations.keys() or architecture not in architectures.keys():\n",
    "            raise ValueError(\"Activation function or architecture not found. Please reconsider.\")\n",
    "        \n",
    "        self.non_linearity = activations[non_linearity]\n",
    "        self.architecture = architectures[architecture]\n",
    "        self.T = T\n",
    "        self.layers = layers\n",
    "       \n",
    "        \n",
    "\n",
    "        blocks1 = []\n",
    "        for _ in range(self.layers):\n",
    "            blocks1.append(nn.Linear(self.input_dim, self.hidden_dim))\n",
    "            blocks1.append(nn.Tanh())\n",
    "\n",
    "        self.layer_functions1 = nn.Sequential(*blocks1)\n",
    "        \n",
    "        blocks2 = []\n",
    "        for _ in range(self.layers):\n",
    "            blocks2.append(nn.Linear(self.input_dim, self.hidden_dim))\n",
    "            blocks2.append(nn.Tanh())\n",
    "\n",
    "        self.layer_functions2 = nn.Sequential(*blocks2)\n",
    "        \n",
    "        \n",
    "        # if self.architecture > 0:\n",
    "        #     ##-- R^{d_aug} -> R^{d_hid} layer -- \n",
    "        #     blocks1 = [nn.Linear(self.input_dim, hidden_dim) for _ in range(self.layers)]\n",
    "        #     self.fc1_time = nn.Sequential(*blocks1) \n",
    "        #     ##-- R^{d_hid} -> R^{d_aug} layer --\n",
    "        #     blocks3 = [nn.Linear(hidden_dim, self.input_dim) for _ in range(self.layers)]\n",
    "        #     self.fc3_time = nn.Sequential(*blocks3)\n",
    "        # else:\n",
    "        #     ##-- R^{d_hid} -> R^{d_hid} layer --\n",
    "        #     blocks = [nn.Linear(hidden_dim, hidden_dim) for _ in range(self.layers)]\n",
    "        #     self.fc2_time = nn.Sequential(*blocks)\n",
    "        \n",
    "    def forward(self, t, x):\n",
    "        \"\"\"\n",
    "        There is no time variable active in this autonomous version\n",
    "        \n",
    "        \"\"\"\n",
    "        if t < self.T/2:\n",
    "            out = self.layer_functions1(x)\n",
    "        else:\n",
    "            out = self.layer_functions2(x)\n",
    "\n",
    "        return out\n",
    "    \n",
    "\n",
    "    \n",
    "dynamics = Dynamics_autonomous(device, data_dim, hidden_dim, augment_dim, non_linearity, architecture, T = T, layers = layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "num_epochs = 80 #number of optimization runs in which the dataset is used for gradient decent\n",
    "l2_factor = 0.02\n",
    "eps = 0.\n",
    "# dynamics = False\n",
    "\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "anode = NeuralODE_justflow(device, data_dim, hidden_dim, augment_dim=augment_dim, non_linearity=non_linearity, \n",
    "                    architecture=architecture, T=T, time_steps=num_steps, fixed_projector=fp, cross_entropy=cross_entropy, dynamics = dynamics)\n",
    "optimizer_anode = torch.optim.Adam(anode.parameters(), lr=1e-3) \n",
    "\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "rnode = NeuralODE_justflow(device, data_dim, hidden_dim, augment_dim=0, non_linearity=non_linearity, \n",
    "                    architecture=architecture, T=T, time_steps=num_steps, fixed_projector=fp, cross_entropy=cross_entropy)\n",
    "optimizer_rnode = torch.optim.Adam(rnode.parameters(), lr=1e-3) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.training import doublebackTrainer\n",
    "#!!added l2 factor\n",
    "trainer_anode = doublebackTrainer(anode, optimizer_anode, device, cross_entropy=cross_entropy, turnpike = turnpike,\n",
    "                         bound=bound, fixed_projector=fp, verbose = True, l2_factor=l2_factor) \n",
    "trainer_anode.train(dataloader, num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from plots.plots import classification_levelsets\n",
    "classification_levelsets(anode)\n",
    "plt.plot(trainer_anode.histories['epoch_loss_history'])\n",
    "plt.xlim(0, len(trainer_anode.histories['epoch_loss_history']) - 1)\n",
    "plt.ylim(0)\n",
    "plt.xlabel('Iterations')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from plots.gifs import trajectory_gif\n",
    "from IPython.display import Image\n",
    "\n",
    "#the function trajectory_gif creates the evolution trajectories of the input data through the network\n",
    "#the passing time corresponds to the depth of the network\n",
    "\n",
    "for X_viz, y_viz in dataloader_viz:\n",
    "    trajectory_gif(anode, X_viz[0:50], y_viz[0:50], timesteps=num_steps, filename = 'trajectory.gif', axlim = 3, dpi = 100)\n",
    "    break\n",
    "\n",
    "#Display of the generated gif\n",
    "traj = Image(filename=\"trajectory.gif\")\n",
    "display(traj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer_rnode = doublebackTrainer(rnode, optimizer_rnode, device, cross_entropy=cross_entropy, turnpike = turnpike,\n",
    "                         bound=bound, fixed_projector=fp, verbose = True, eps = eps, db_type='l2') \n",
    "# trainer_rnode.train(dataloader, num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from plots.plots import classification_levelsets\n",
    "classification_levelsets(rnode)\n",
    "plt.plot(trainer_rnode.histories['epoch_loss_history'])\n",
    "plt.xlim(0, len(trainer_rnode.histories['epoch_loss_history']) - 1)\n",
    "plt.ylim(0)\n",
    "plt.xlabel('Iterations')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from plots.plots import classification_levelsets\n",
    "import os\n",
    "\n",
    "if not os.path.exists(subfolder):\n",
    "        os.makedirs(subfolder)\n",
    "        \n",
    "footnote = f'{num_epochs = }, {num_steps = }, {data_noise = }'\n",
    "        \n",
    "fig_name_base = os.path.join(subfolder, 'levelsets')\n",
    "classification_levelsets(anode, fig_name_base, footnote = footnote + 'eps = 0')\n",
    "classification_levelsets(rnode, fig_name_base + '_rob', footnote = footnote + f'{eps = }')\n",
    "from IPython.display import Image\n",
    "img1 = Image(filename = fig_name_base + '.png', width = 400)\n",
    "img2 = Image(filename = fig_name_base + '_rob.png', width = 400)\n",
    "\n",
    "display(img1,img2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(trainer_anode.histories['epoch_loss_history'])\n",
    "plt.xlim(0, len(trainer_anode.histories['epoch_loss_history']) - 1)\n",
    "plt.ylim(0)\n",
    "plt.xlabel('Iterations')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(trainer_rnode.histories['epoch_loss_history'])\n",
    "plt.xlim(0, len(trainer_rnode.histories['epoch_loss_history']) - 1)\n",
    "plt.ylim(0)\n",
    "plt.xlabel('Iterations')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for X_viz, y_viz in dataloader_viz:\n",
    "    X_viz = X_viz[0:5]\n",
    "    break\n",
    "\n",
    "trajectories = anode.flow.trajectory(X_viz, 10).detach()\n",
    "print(X_viz)\n",
    "print(trajectories.size()) #time is in the first coordinate\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from plots.gifs import trajectory_gif\n",
    "\n",
    "#the function trajectory_gif creates the evolution trajectories of the input data through the network\n",
    "#the passing time corresponds to the depth of the network\n",
    "\n",
    "for X_viz, y_viz in dataloader_viz:\n",
    "    trajectory_gif(anode, X_viz[0:50], y_viz[0:50], timesteps=num_steps, filename = 'trajectory.gif', axlim = 3, dpi = 100)\n",
    "    trajectory_gif(rnode, X_viz[0:50], y_viz[0:50], timesteps=num_steps, filename = 'trajectory_db.gif', axlim = 3, dpi = 100)\n",
    "    break\n",
    "\n",
    "#Display of the generated gif\n",
    "traj = Image(filename=\"trajectory.gif\")\n",
    "rtraj = Image(filename=\"trajectory_db.gif\")\n",
    "display(traj, rtraj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "from plots.plots import comparison_plot\n",
    "# traj = Image(filename=\"trajectory19.png\", retina = True)\n",
    "# rtraj = Image(filename=\"trajectory_db19.png\", retina = True)\n",
    "# display(traj, rtraj)\n",
    "\n",
    "comparison_plot(\"trajectory39.png\", 'standard training', \"trajectory_db39.png\", 'robust training', 'traj_comp.png')\n",
    "display(Image('traj_comp.png', width = 800))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I want to visualize the separation boundary in the final linear layer."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "neuralODE",
   "language": "python",
   "name": "neuralode"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "vscode": {
   "interpreter": {
    "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
