{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Late robustness\n",
    "\n",
    "During the model training, we activate the robustness term only after the model expresses the basic topology of the data\n",
    "In the robustness phase the decision boundaries are then diffused and robustified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Juptyer magic: For export. Makes the plots size right for the screen \n",
    "%matplotlib inline\n",
    "# %config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "%config InlineBackend.figure_formats = ['svg'] \n",
    "\n",
    "\n",
    "torch.backends.cudnn.deterministic = True\n",
    "seed = np.random.randint(1,200)\n",
    "# seed = 56\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "print(seed)\n",
    "g = torch.Generator()\n",
    "g.manual_seed(seed)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_noise = 0.2\n",
    "plotlim = [-3, 3]\n",
    "subfolder = 'moons'\n",
    "\n",
    "\n",
    "from models.training import create_dataloader\n",
    "dataloader, dataloader_viz = create_dataloader('moons', noise = data_noise, plotlim = plotlim, random_state = seed, label = 'vector')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x_batch, y_batch in dataloader:\n",
    "    print(x_batch, y_batch)\n",
    "    print(y_batch[0:20].size())\n",
    "    \n",
    "    print(len(y_batch.shape) > 1)\n",
    "    break"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model dynamics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import of the model dynamics that describe the neural ODE\n",
    "#The dynamics are based on the torchdiffeq package, that implements ODE solvers in the pytorch setting\n",
    "from models.neural_odes import NeuralODE\n",
    "\n",
    "#for neural ODE based networks the network width is constant. In this example the input is 2 dimensional\n",
    "hidden_dim, data_dim = 2, 2 \n",
    "augment_dim = 0\n",
    "\n",
    "#T is the end time of the neural ODE evolution, num_steps are the amount of discretization steps for the ODE solver\n",
    "T, num_steps = 20, 20\n",
    "bound = 0.\n",
    "fp = False #this recent change made things not work anymore\n",
    "cross_entropy = False #this leads to squared loss in the training\n",
    "turnpike = False\n",
    "\n",
    "non_linearity = 'tanh' #'relu' #\n",
    "architecture = 'inside' #outside\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and generating level sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "num_epochs = 80 #number of optimization runs in which the dataset is used for gradient decent\n",
    "eps = 0.2\n",
    "\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "anode = NeuralODE(device, data_dim, hidden_dim, augment_dim=augment_dim, non_linearity=non_linearity, \n",
    "                    architecture=architecture, T=T, time_steps=num_steps, fixed_projector=fp, cross_entropy=cross_entropy)\n",
    "optimizer_anode = torch.optim.Adam(anode.parameters(), lr=1e-3) \n",
    "\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "rnode = NeuralODE(device, data_dim, hidden_dim, augment_dim=0, non_linearity=non_linearity, \n",
    "                    architecture=architecture, T=T, time_steps=num_steps, fixed_projector=fp, cross_entropy=cross_entropy)\n",
    "optimizer_rnode = torch.optim.Adam(rnode.parameters(), lr=1e-3) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.training import doublebackTrainer\n",
    "\n",
    "trainer_anode = doublebackTrainer(anode, optimizer_anode, device, cross_entropy=cross_entropy, turnpike = turnpike,\n",
    "                         bound=bound, fixed_projector=fp, verbose = True, eps_comp = 0.2) \n",
    "trainer_anode.train(dataloader, num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from plots.plots import classification_levelsets\n",
    "classification_levelsets(anode)\n",
    "plt.plot(trainer_anode.histories['epoch_loss_history'])\n",
    "plt.xlim(0, len(trainer_anode.histories['epoch_loss_history']) - 1)\n",
    "plt.ylim(0)\n",
    "plt.xlabel('Iterations')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from plots.gifs import trajectory_gif\n",
    "from IPython.display import Image\n",
    "\n",
    "#the function trajectory_gif creates the evolution trajectories of the input data through the network\n",
    "#the passing time corresponds to the depth of the network\n",
    "\n",
    "for X_viz, y_viz in dataloader_viz:\n",
    "    trajectory_gif(anode, X_viz[0:50], y_viz[0:50], timesteps=num_steps, filename = 'trajectory.gif', axlim = 8, dpi = 100)\n",
    "    break\n",
    "\n",
    "#Display of the generated gif\n",
    "traj = Image(filename=\"trajectory.gif\")\n",
    "display(traj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "   \n",
    "w = anode.linear_layer.weight\n",
    "b = anode.linear_layer.bias\n",
    "\n",
    "print(w)\n",
    "print(b)\n",
    "\n",
    "rnode.linear_layer.weight = w\n",
    "rnode.linear_layer.bias = b\n",
    "\n",
    "rnode.linear_layer.requires_grad =  False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer_rnode = doublebackTrainer(rnode, optimizer_rnode, device, cross_entropy=cross_entropy, turnpike = turnpike,\n",
    "                         bound=bound, fixed_projector=fp, verbose = True, eps = eps, db_type='l2') \n",
    "trainer_rnode.train(dataloader, num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from plots.plots import classification_levelsets\n",
    "classification_levelsets(rnode)\n",
    "plt.plot(trainer_rnode.histories['epoch_loss_history'])\n",
    "plt.xlim(0, len(trainer_rnode.histories['epoch_loss_history']) - 1)\n",
    "plt.ylim(0)\n",
    "plt.xlabel('Iterations')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from plots.plots import classification_levelsets\n",
    "import os\n",
    "\n",
    "if not os.path.exists(subfolder):\n",
    "        os.makedirs(subfolder)\n",
    "        \n",
    "footnote = f'{num_epochs = }, {num_steps = }, {data_noise = }'\n",
    "        \n",
    "fig_name_base = os.path.join(subfolder, 'levelsets')\n",
    "classification_levelsets(anode, fig_name_base, footnote = footnote + 'eps = 0')\n",
    "classification_levelsets(rnode, fig_name_base + '_rob', footnote = footnote + f'{eps = }')\n",
    "from IPython.display import Image\n",
    "img1 = Image(filename = fig_name_base + '.png', width = 400)\n",
    "img2 = Image(filename = fig_name_base + '_rob.png', width = 400)\n",
    "\n",
    "display(img1,img2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(trainer_anode.histories['epoch_loss_history'])\n",
    "plt.xlim(0, len(trainer_anode.histories['epoch_loss_history']) - 1)\n",
    "plt.ylim(0)\n",
    "plt.xlabel('Iterations')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(trainer_rnode.histories['epoch_loss_history'])\n",
    "plt.xlim(0, len(trainer_rnode.histories['epoch_loss_history']) - 1)\n",
    "plt.ylim(0)\n",
    "plt.xlabel('Iterations')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for X_viz, y_viz in dataloader_viz:\n",
    "    X_viz = X_viz[0:5]\n",
    "    break\n",
    "\n",
    "trajectories = anode.flow.trajectory(X_viz, 10).detach()\n",
    "print(X_viz)\n",
    "print(trajectories.size()) #time is in the first coordinate\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lyapunov exponent computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "input: two trajectories x(t), y(t) where each has size (x_dim,len_t)\n",
    "output: maximum lyapunov exponent for each time t, size (1,len_t)'''\n",
    "def le(x,y,t):\n",
    "    d = x - y\n",
    "    d = torch.linalg.norm(x - y, dim = 0)\n",
    "    # print(f'{d.shape = }')\n",
    "    d = d/d[0]\n",
    "    d = np.log(d)\n",
    "    \n",
    "\n",
    "    d = d/t\n",
    "    return d\n",
    "\n",
    "\n",
    "\n",
    "'''\n",
    "Compute the maximum Lyapunov exponent with initial value tolerance eps\n",
    "input: \n",
    "trajectories of size (x_amount,x_amount,x_dim,time_dim)\n",
    "each trajectory has initial value x_0 = traj[i,j,:,0]\n",
    "\n",
    "output:\n",
    "MLE for each trajectory as averaged LE for all initial values that is eps close to the initial value\n",
    "output size (x_amount,x_amount,t_dim)\n",
    "'''\n",
    "def MLE(traj, t, eps = 0.1):\n",
    "    x_amount = traj.size(0)\n",
    "    x_amount, y_amount, x_dim, t_dim = traj.shape\n",
    "    le_val = torch.zeros((x_amount, y_amount, t_dim)) \n",
    "    print(f'{le_val.shape = }')\n",
    "    for i in range(x_amount):\n",
    "        for j in range(y_amount):\n",
    "            count = 0\n",
    "            for i_comp in range(x_amount):\n",
    "                for j_comp in range(y_amount):\n",
    "                    if (torch.norm(traj[i,j,:,0] - traj[i_comp,j_comp,:,0]) < eps and not(i == i_comp and j == j_comp)):\n",
    "                        count += 1\n",
    "                        le_val[i,j] += le(traj[i,j,:,:],traj[i_comp,j_comp,:,:],t)\n",
    "                        print('avg le update with count ',count,' and value ',le_val[i,j,-1])\n",
    "            if count > 1:\n",
    "                le_val[i,j,:] = le_val[i,j,:]/count\n",
    "    return le_val\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "x_amount = 70\n",
    "eps = 0.08\n",
    "t = torch.linspace(0,T,2) #only take initial and final time for MLE\n",
    "\n",
    "\n",
    "x = torch.linspace(-2,2,x_amount)\n",
    "y = torch.linspace(-2,2,x_amount)\n",
    "X, Y = torch.meshgrid(x, y)\n",
    "\n",
    "inputs = torch.stack([X,Y], dim=-1)\n",
    "print(f'{inputs.size() = }')\n",
    "# print(inputs)\n",
    "\n",
    "trajectories = anode.flow.trajectory(inputs, num_steps).detach()\n",
    "t_indices = torch.tensor([0,-1])\n",
    "\n",
    "trajectories = trajectories[t_indices] #only take the initial and final time of the trajectory\n",
    "print('shape of trajectories of grid', trajectories.shape) #MLE works with the time in the last dimension\n",
    "trajectories = trajectories.permute(1,2,3,0)\n",
    "print('shape of permuted traj of grid', trajectories.shape) #this fits with the MLE function\n",
    "\n",
    "output = MLE(trajectories,t,eps)\n",
    "print(output)\n",
    "output = output[:,:,-1] #reduce to last time instance T\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create heatmap using imshow\n",
    "anodeimg = plt.imshow(np.rot90(output), origin='upper', extent=(-2, 2, -2, 2), cmap='viridis')\n",
    "vmin, vmax = anodeimg.get_clim()\n",
    "plt.colorbar()  # Show color scale\n",
    "plt.savefig('MLE.png',bbox_inches='tight', dpi=300, format='png', facecolor = 'white')\n",
    "plt.close()\n",
    "\n",
    "img1 = Image(filename = fig_name_base + '.png', width = 400)\n",
    "img2 = Image(filename = 'MLE.png', width = 400)\n",
    "\n",
    "display(img1,img2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rtrajectories = rnode.flow.trajectory(inputs, num_steps).detach()\n",
    "t_indices = torch.tensor([0,-1])\n",
    "\n",
    "\n",
    "rtrajectories = rtrajectories[t_indices] #only take the initial and final time of the trajectory\n",
    "print('shape of trajectories of grid', trajectories.shape) #MLE works with the time in the last dimension\n",
    "rtrajectories = rtrajectories.permute(1,2,3,0)\n",
    "print('shape of permuted traj of grid', trajectories.shape) #this fits with the MLE function\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "routput = MLE(rtrajectories,t,eps)\n",
    "print(routput)\n",
    "routput = routput[:,:,-1] #reduce to last time instance T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create heatmap using imshow\n",
    "\n",
    "plt.imshow(np.rot90(routput), origin='upper', extent=(-2, 2, -2, 2), cmap='viridis')\n",
    "plt.clim(vmin,vmax)\n",
    "plt.colorbar()  # Show color scale\n",
    "plt.savefig('MLE_rob.png',bbox_inches='tight', dpi=300, format='png', facecolor = 'white')\n",
    "plt.close()\n",
    "\n",
    "img1 = Image(filename = fig_name_base + '_rob' + '.png', width = 400)\n",
    "img2 = Image(filename = 'MLE_rob.png', width = 400)\n",
    "\n",
    "display(img1,img2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# img1 = Image(filename = fig_name_base + '.png', width = 400)\n",
    "img2 = Image(filename = 'MLE.png', width = 400)\n",
    "# img3 = Image(filename = fig_name_base + '_rob' + '.png', width = 400)\n",
    "img4 = Image(filename = 'MLE_rob.png', width = 400)\n",
    "\n",
    "display(img2,img4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MLE_test(output, x, y, fig_name=None, footnote=None, contour = True, plotlim = [-1, 1], filename = None):\n",
    "    \n",
    "    \n",
    "    fig = plt.figure(figsize=(5, 5), dpi=100)\n",
    "\n",
    "\n",
    "    x1lower, x1upper = -2, 2\n",
    "    x2lower, x2upper = -2, 2\n",
    "\n",
    "    # model_inputs = torch.stack([x, y], dim=-1)\n",
    "\n",
    "\n",
    "\n",
    "    plt.grid(False)\n",
    "    plt.xlim([x1lower, x1upper])\n",
    "    plt.ylim([x2lower, x2upper])\n",
    "\n",
    "    ax = plt.gca()\n",
    "    ax.set_aspect('equal') \n",
    "\n",
    "\n",
    "\n",
    "    z = np.array(output).reshape(x.shape)\n",
    "\n",
    "    levels = np.linspace(vmin,vmax,40).tolist()\n",
    "\n",
    "    cont = plt.contourf(x, y, z, levels, alpha=1, zorder = 0, extent=(x1lower, x1upper, x2lower, x2upper)) #plt.get_cmap('coolwarm')\n",
    "    cbar = fig.colorbar(cont, fraction=0.046, pad=0.04)\n",
    "    cbar.ax.set_ylabel('First Lyapunov Exponent')\n",
    "    if filename:\n",
    "        plt.savefig(filename + '.png',bbox_inches='tight', dpi=400, format='png', facecolor = 'white')\n",
    "        plt.close()\n",
    "\n",
    "x = torch.linspace(-2,2,x_amount)\n",
    "y = torch.linspace(-2,2,x_amount)\n",
    "X, Y = torch.meshgrid(x, y)  \n",
    "    \n",
    "MLE_test(output, X, Y, filename = 'LE')\n",
    "MLE_test(routput, X, Y, filename = 'robust_LE')\n",
    "\n",
    "\n",
    "img_a = Image(filename = 'LE.png', width = 400)\n",
    "img_b = Image(filename = 'robust_LE.png', width = 400)\n",
    "\n",
    "display(img_a,img_b)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from plots.gifs import trajectory_gif\n",
    "\n",
    "#the function trajectory_gif creates the evolution trajectories of the input data through the network\n",
    "#the passing time corresponds to the depth of the network\n",
    "\n",
    "for X_viz, y_viz in dataloader_viz:\n",
    "    trajectory_gif(anode, X_viz[0:50], y_viz[0:50], timesteps=num_steps, filename = 'trajectory.gif', axlim = 8, dpi = 100)\n",
    "    trajectory_gif(rnode, X_viz[0:50], y_viz[0:50], timesteps=num_steps, filename = 'trajectory_db.gif', axlim = 8, dpi = 100)\n",
    "    break\n",
    "\n",
    "#Display of the generated gif\n",
    "traj = Image(filename=\"trajectory.gif\")\n",
    "rtraj = Image(filename=\"trajectory_db.gif\")\n",
    "display(traj, rtraj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "from plots.plots import comparison_plot\n",
    "# traj = Image(filename=\"trajectory19.png\", retina = True)\n",
    "# rtraj = Image(filename=\"trajectory_db19.png\", retina = True)\n",
    "# display(traj, rtraj)\n",
    "\n",
    "comparison_plot(\"trajectory39.png\", 'standard training', \"trajectory_db39.png\", 'robust training', 'traj_comp.png')\n",
    "display(Image('traj_comp.png', width = 800))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I want to visualize the separation boundary in the final linear layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rc\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "import seaborn as sns\n",
    "from matplotlib.colors import to_rgb\n",
    "import imageio\n",
    "\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "import os\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def linlayer_levelsets(model, fig_name=None, footnote=None, contour = True, plotlim = [-2, 2]):\n",
    "    \n",
    "    \n",
    "    x1lower, x1upper = plotlim\n",
    "    x2lower, x2upper = plotlim\n",
    "\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "    fig = plt.figure(figsize=(5, 5), dpi=100)\n",
    "    \n",
    "    plt.ylabel(r\"$x_2$\")\n",
    "    plt.xlabel(r\"$x_1$\")\n",
    "    plt.figtext(0.5, 0, footnote, ha=\"center\", fontsize=10)\n",
    "\n",
    "    \n",
    "   \n",
    "    model.to(device)\n",
    "\n",
    "    x1 = torch.arange(x1lower, x1upper, step=0.01, device=device)\n",
    "    x2 = torch.arange(x2lower, x2upper, step=0.01, device=device)\n",
    "    xx1, xx2 = torch.meshgrid(x1, x2)  # Meshgrid function as in numpy\n",
    "    model_inputs = torch.stack([xx1, xx2], dim=-1)\n",
    "    \n",
    "    preds = model.linear_layer(model_inputs)\n",
    "    \n",
    "    # dim = 2 means that it normalizes along the last dimension, i.e. along the two predictions that are the model output\n",
    "    m = nn.Softmax(dim=2)\n",
    "    # softmax normalizes the model predictions to probabilities\n",
    "    preds = m(preds)\n",
    "\n",
    "    #we only need the probability for being in class1 (as prob for class2 is then 1- class1)\n",
    "    preds = preds[:, :, 0]\n",
    "    preds = preds.unsqueeze(2)  # adds a tensor dimension at position 2\n",
    "    \n",
    "    plt.grid(False)\n",
    "    plt.xlim([x1lower, x1upper])\n",
    "    plt.ylim([x2lower, x2upper])\n",
    "\n",
    "    ax = plt.gca()\n",
    "    ax.set_aspect('equal') \n",
    "    \n",
    "    if contour:\n",
    "        colors = [to_rgb(\"C1\"), [1, 1, 1], to_rgb(\"C0\")] # first color is orange, last is blue\n",
    "        cm = LinearSegmentedColormap.from_list(\n",
    "            \"Custom\", colors, N=40)\n",
    "        z = np.array(preds).reshape(xx1.shape)\n",
    "        \n",
    "        levels = np.linspace(0.,1.,20).tolist()\n",
    "        \n",
    "        cont = plt.contourf(xx1, xx2, z, levels, alpha=1, cmap=cm, zorder = 0, extent=(x1lower, x1upper, x2lower, x2upper)) #plt.get_cmap('coolwarm')\n",
    "        cbar = fig.colorbar(cont, fraction=0.046, pad=0.04)\n",
    "        cbar.ax.set_ylabel('prediction prob.')\n",
    "    \n",
    "\n",
    "    if fig_name:\n",
    "        plt.savefig(fig_name + '.png', bbox_inches='tight', dpi=300, format='png', facecolor = 'white')\n",
    "        plt.clf()\n",
    "        plt.close()\n",
    "    # else: plt.show()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linlayer_levelsets(anode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def trajectory_gif_new(model, inputs, targets, timesteps, dpi=200, alpha=0.9,\n",
    "                   alpha_line=1, filename='trajectory.gif', axlim = 0):\n",
    "    \n",
    "    from matplotlib import rc\n",
    "    from scipy.interpolate import interp1d\n",
    "    rc(\"text\", usetex = False)\n",
    "    font = {'size'   : 18}\n",
    "    rc('font', **font)\n",
    "\n",
    "    if not filename.endswith(\".gif\"):\n",
    "        raise RuntimeError(\"Name must end in with .gif, but ends with {}\".format(filename))\n",
    "    base_filename = filename[:-4]\n",
    "\n",
    "    ## We focus on 3 colors at most\n",
    "    if False in (t < 2 for t in targets): \n",
    "        color = ['mediumpurple' if targets[i] == 2.0 else 'gold' if targets[i] == 0.0 else 'mediumseagreen' for i in range(len(targets))]\n",
    "    else:\n",
    "        #color = ['crimson' if targets[i, 0] > 0.0 else 'dodgerblue' for i in range(len(targets))]\n",
    "        color = ['C1' if targets[i] > 0.0 else 'dimgrey' for i in range(len(targets))]\n",
    "\n",
    "    trajectories = model.flow.trajectory(inputs, timesteps).detach()\n",
    "    num_dims = trajectories.shape[2]\n",
    "\n",
    "    if axlim == 0:        \n",
    "        x_min, x_max = trajectories[:, :, 0].min(), trajectories[:, :, 0].max()\n",
    "        y_min, y_max = trajectories[:, :, 1].min(), trajectories[:, :, 1].max()\n",
    "    else: \n",
    "        x_min, x_max = -axlim, axlim  #to normalize for rob and standard nODE\n",
    "        y_min, y_max = -axlim, axlim   #\n",
    "        \n",
    "    if num_dims == 3:\n",
    "        z_min, z_max = trajectories[:, :, 2].min(), trajectories[:, :, 2].max()\n",
    "    margin = 0.1\n",
    "    x_range = x_max - x_min\n",
    "    y_range = y_max - y_min\n",
    "    x_min -= margin * x_range\n",
    "    x_max += margin * x_range\n",
    "    y_min -= margin * y_range\n",
    "    y_max += margin * y_range\n",
    "    if num_dims == 3:\n",
    "        z_range = z_max - z_min\n",
    "        z_min -= margin * z_range\n",
    "        z_max += margin * z_range\n",
    "        \n",
    "    T = model.T \n",
    "    integration_time = torch.linspace(0.0, T, timesteps)\n",
    "    \n",
    "    interp_x = []\n",
    "    interp_y = []\n",
    "    interp_z = []\n",
    "    for i in range(inputs.shape[0]):\n",
    "        interp_x.append(interp1d(integration_time, trajectories[:, i, 0], kind='cubic', fill_value='extrapolate'))\n",
    "        interp_y.append(interp1d(integration_time, trajectories[:, i, 1], kind='cubic', fill_value='extrapolate'))\n",
    "        if num_dims == 3:\n",
    "            interp_z.append(interp1d(integration_time, trajectories[:, i, 2], kind='cubic', fill_value='extrapolate'))\n",
    "    \n",
    "    interp_time = 20\n",
    "    # interp_time = 3 #this was 5 before\n",
    "    _time = torch.linspace(0., T, interp_time)\n",
    "\n",
    "    plt.rc('grid', linestyle=\"dotted\", color='lightgray')\n",
    "    for t in range(interp_time):\n",
    "        if num_dims == 2:\n",
    "            fig = plt.figure()\n",
    "            ax = fig.add_subplot(1, 1, 1)\n",
    "            label_size = 13\n",
    "            plt.rcParams['xtick.labelsize'] = label_size\n",
    "            plt.rcParams['ytick.labelsize'] = label_size \n",
    "            ax.set_axisbelow(True)\n",
    "            ax.xaxis.grid(color='lightgray', linestyle='dotted')\n",
    "            ax.yaxis.grid(color='lightgray', linestyle='dotted')\n",
    "            ax.set_facecolor('whitesmoke')\n",
    "            \n",
    "            plt.xlim(x_min, x_max)\n",
    "            plt.ylim(y_min, y_max)\n",
    "            plt.rc('text', usetex=False)\n",
    "            plt.rc('font', family='serif')\n",
    "            plt.xlabel(r'$x_1$', fontsize=12)\n",
    "            plt.ylabel(r'$x_2$', fontsize=12)\n",
    "            \n",
    "            x1 = torch.arange(x_min, x_max, step=0.01, device=device)\n",
    "            x2 = torch.arange(y_min, y_max, step=0.01, device=device)\n",
    "            xx1, xx2 = torch.meshgrid(x1, x2)  # Meshgrid function as in numpy\n",
    "            model_inputs = torch.stack([xx1, xx2], dim=-1)\n",
    "            \n",
    "            preds = model.linear_layer(model_inputs)\n",
    "            \n",
    "            # dim = 2 means that it normalizes along the last dimension, i.e. along the two predictions that are the model output\n",
    "            m = nn.Softmax(dim=2)\n",
    "            # softmax normalizes the model predictions to probabilities\n",
    "            preds = m(preds)\n",
    "\n",
    "            #we only need the probability for being in class1 (as prob for class2 is then 1- class1)\n",
    "            preds = preds[:, :, 0]\n",
    "            preds = preds.unsqueeze(2)  # adds a tensor dimension at position 2\n",
    "            \n",
    "            plt.grid(False)\n",
    "    \n",
    "\n",
    "            ax = plt.gca()\n",
    "            ax.set_aspect('equal') \n",
    "            \n",
    "            \n",
    "            colors = [to_rgb(\"C1\"), [1, 1, 1], to_rgb(\"C0\")] # first color is orange, last is blue\n",
    "            cm = LinearSegmentedColormap.from_list(\n",
    "                \"Custom\", colors, N=40)\n",
    "            z = np.array(preds).reshape(xx1.shape)\n",
    "            \n",
    "            levels = np.linspace(0.,1.,15).tolist()\n",
    "            \n",
    "            cont = plt.contourf(xx1, xx2, z, levels, alpha=0.5, cmap=cm, zorder = 0, extent=(x_min, x_max, y_min, y_max)) #plt.get_cmap('coolwarm')\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            plt.scatter([x(_time)[t] for x in interp_x], \n",
    "                         [y(_time)[t] for y in interp_y], \n",
    "                         c=color, alpha=alpha, marker = 'o', linewidth=0.65, edgecolors='black', zorder=3)\n",
    "\n",
    "            if t > 0:\n",
    "                for i in range(inputs.shape[0]):\n",
    "                    x_traj = interp_x[i](_time)[:t+1]\n",
    "                    y_traj = interp_y[i](_time)[:t+1]\n",
    "                    plt.plot(x_traj, y_traj, c=color[i], alpha=alpha_line, linewidth = 0.75, zorder=1)\n",
    "            \n",
    "        \n",
    "        ax.set_aspect('equal')\n",
    "\n",
    "        plt.savefig(base_filename + \"{}.png\".format(t),\n",
    "                    format='png', dpi=dpi, bbox_inches='tight', facecolor = 'white')\n",
    "        # Save only 3 frames (.pdf for paper)\n",
    "        # if t in [0, interp_time//5, interp_time//2, interp_time-1]:\n",
    "        #     plt.savefig(base_filename + \"{}.pdf\".format(t), format='pdf', bbox_inches='tight')\n",
    "        plt.clf()\n",
    "        plt.close()\n",
    "\n",
    "    imgs = []\n",
    "    for i in range(interp_time):\n",
    "        img_file = base_filename + \"{}.png\".format(i)\n",
    "        imgs.append(imageio.imread(img_file))\n",
    "        if i not in [0, interp_time//5, interp_time//2, interp_time-1]: os.remove(img_file) \n",
    "    imageio.mimwrite(filename, imgs, fps = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from plots.gifs import trajectory_gif\n",
    "\n",
    "#the function trajectory_gif creates the evolution trajectories of the input data through the network\n",
    "#the passing time corresponds to the depth of the network\n",
    "\n",
    "data_iter = iter(dataloader)\n",
    "X,y = next(data_iter)\n",
    "batch_size = 40\n",
    "\n",
    "X_viz = torch.zeros_like(X[0:batch_size])\n",
    "y_viz = torch.zeros(batch_size)\n",
    "print(y_viz.size())\n",
    "print(X_viz.size())\n",
    "X_viz[:,1] = torch.linspace(-5,5,batch_size)\n",
    "X_viz[:,0] = torch.tensor([0])\n",
    "print(X_viz)\n",
    "\n",
    "# plt.scatter(X_viz[:,0],X_viz[:,1])\n",
    "\n",
    "trajectory_gif_new(anode, X_viz[0:batch_size], y_viz[0:batch_size], timesteps=num_steps, filename = 'trajectory.gif', axlim = 8, dpi = 100)\n",
    "trajectory_gif_new(rnode, X_viz[0:batch_size], y_viz[0:batch_size], timesteps=num_steps, filename = 'trajectory_db.gif', axlim = 8, dpi = 100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traj = Image(filename=\"trajectory.gif\")\n",
    "rtraj = Image(filename=\"trajectory_db.gif\")\n",
    "display(traj, rtraj)\n",
    "\n",
    "comparison_plot(\"trajectory19.png\", 'standard training', \"trajectory_db19.png\", 'robust training', 'traj_comp.png')\n",
    "display(Image('traj_comp.png', width = 800))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for X_viz, y_viz in dataloader_viz:\n",
    "    trajectory_gif_new(anode, X_viz, y_viz, timesteps=num_steps, filename = 'trajectory.gif', axlim = 8, dpi = 100)\n",
    "    trajectory_gif_new(rnode, X_viz, y_viz, timesteps=num_steps, filename = 'trajectory_db.gif', axlim = 8, dpi = 100)\n",
    "    break\n",
    "\n",
    "#Display of the generated gif\n",
    "traj = Image(filename=\"trajectory.gif\")\n",
    "rtraj = Image(filename=\"trajectory_db.gif\")\n",
    "display(traj, rtraj)\n",
    "\n",
    "comparison_plot(\"trajectory19.png\", 'standard training', \"trajectory_db19.png\", 'robust training', 'traj_comp.png')\n",
    "display(Image('traj_comp.png', width = 800))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "neuralODE",
   "language": "python",
   "name": "neuralode"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "vscode": {
   "interpreter": {
    "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
