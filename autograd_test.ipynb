{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computing the Maximum Lyapunov Exponent via displacement\n",
    "\n",
    "We compare the MLE for standard training and robust training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Juptyer magic: For export. Makes the plots size right for the screen \n",
    "%matplotlib inline\n",
    "# %config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "%config InlineBackend.figure_formats = ['svg'] \n",
    "\n",
    "\n",
    "torch.backends.cudnn.deterministic = True\n",
    "seed = np.random.randint(1,200)\n",
    "seed = 57\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "print(seed)\n",
    "g = torch.Generator()\n",
    "g.manual_seed(seed)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_entropy = False #this leads to squared loss in the training\n",
    "data_noise = 0.1\n",
    "batch_size = 5000\n",
    "plotlim = [-3, 3]\n",
    "subfolder = 'traj_moons'\n",
    "\n",
    "\n",
    "if cross_entropy == True:\n",
    "    label = 'scalar'\n",
    "else: label = 'vector'\n",
    "\n",
    "\n",
    "from models.training import create_dataloader\n",
    "dataloader, dataloader_viz = create_dataloader('moons', noise = data_noise, batch_size = batch_size, plotlim = plotlim, random_state = seed, label = label)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model dynamics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import of the model dynamics that describe the neural ODE\n",
    "#The dynamics are based on the torchdiffeq package, that implements ODE solvers in the pytorch setting\n",
    "from models.neural_odes import NeuralODE\n",
    "\n",
    "#for neural ODE based networks the network width is constant. In this example the input is 2 dimensional\n",
    "hidden_dim, data_dim = 2, 2 \n",
    "augment_dim = 0\n",
    "\n",
    "#T is the end time of the neural ODE evolution, num_steps are the amount of discretization steps for the ODE solver\n",
    "T, num_steps = 1, 10\n",
    "bound = 0.\n",
    "fp = False #this recent change made things not work anymore\n",
    "turnpike = False\n",
    "\n",
    "non_linearity = 'tanh' #'relu' #\n",
    "architecture = 'outside' #outside\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and generating level sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "num_epochs = 100 #number of optimization runs in which the dataset is used for gradient decent\n",
    "eps = 0.\n",
    "\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "anode = NeuralODE(device, data_dim, hidden_dim, augment_dim=augment_dim, non_linearity=non_linearity, \n",
    "                    architecture=architecture, T=T, time_steps=num_steps, fixed_projector=fp, cross_entropy=cross_entropy)\n",
    "optimizer_anode = torch.optim.Adam(anode.parameters(), lr=1e-3) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.training import doublebackTrainer\n",
    "\n",
    "trainer_anode = doublebackTrainer(anode, optimizer_anode, device, cross_entropy=cross_entropy, turnpike = turnpike,\n",
    "                         bound=bound, fixed_projector=fp, verbose = True, eps_comp = 0.2) \n",
    "trainer_anode.train(dataloader, num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from plots.plots import classification_levelsets\n",
    "classification_levelsets(anode)\n",
    "plt.plot(trainer_anode.histories['epoch_loss_history'])\n",
    "plt.xlim(0, len(trainer_anode.histories['epoch_loss_history']) - 1)\n",
    "plt.ylim(0)\n",
    "plt.xlabel('Iterations')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define inputs\n",
    "input1 = torch.tensor([1, 0], dtype=torch.float32)\n",
    "input2 = torch.tensor([0, 1], dtype=torch.float32)\n",
    "time_interval = torch.tensor([0, T], dtype=torch.float32)\n",
    "\n",
    "def input_to_output(input):\n",
    "    return anode.flow(input, time_interval)[-1]\n",
    "\n",
    "def max_singular_value(input):\n",
    "    # Compute the Jacobian matrix\n",
    "    J = torch.autograd.functional.jacobian(input_to_output, input)\n",
    "    \n",
    "    # Perform Singular Value Decomposition\n",
    "    U, S, V = torch.svd(J)\n",
    "    \n",
    "    # Return the maximum singular value\n",
    "    return torch.max(S)\n",
    "\n",
    "max_singular_value(input1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_amount = 100\n",
    "\n",
    "\n",
    "x = torch.linspace(-2,2,x_amount)\n",
    "y = torch.linspace(-2,2,x_amount)\n",
    "X, Y = torch.meshgrid(x, y)\n",
    "\n",
    "inputs = torch.stack([X,Y], dim=-1)\n",
    "inputs = inputs.view(-1,2) #to be able to loop through all the grid values\n",
    "inputs_MLE = torch.zeros(x_amount * x_amount)\n",
    "\n",
    "\n",
    "\n",
    "for i, input in enumerate(inputs):\n",
    "        \n",
    "        inputs_MLE[i] = 1/T * np.log(max_singular_value(input))\n",
    "    \n",
    "    \n",
    "output = inputs_MLE.view(x_amount,x_amount)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.colors import CenteredNorm, to_rgba, LinearSegmentedColormap\n",
    "from IPython.display import Image\n",
    "\n",
    "viridis = plt.get_cmap('viridis', 256)\n",
    "colors = viridis(np.linspace(0, 1, 256))\n",
    "colors[-1] = to_rgba('red')  # Change the last color to red\n",
    "indices = [0,-1]\n",
    "colors_new = colors[indices]\n",
    "custom_cmap = LinearSegmentedColormap.from_list(\"custom_viridis\", colors_new)\n",
    "\n",
    "# colors = [to_rgb(\"darkblue\"), to_rgb('grey'), to_rgb('red')] # first color is orange, last is blue\n",
    "# custom_cmap = LinearSegmentedColormap.from_list(\n",
    "#     \"Custom\", colors, N=40)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "anodeimg = plt.imshow(np.rot90(output), origin='upper', extent=(-2, 2, -2, 2),cmap = 'viridis')#, norm=CenteredNorm(vcenter=0)) # cmap='viridis')\n",
    "vmin, vmax = anodeimg.get_clim()\n",
    "plt.colorbar()  # Show color scale\n",
    "plt.savefig('MLE.png',bbox_inches='tight', dpi=300, format='png', facecolor = 'white')\n",
    "plt.close()\n",
    "\n",
    "# img1 = Image(filename = fig_name_base + '.png', width = 400)\n",
    "img2 = Image(filename = 'MLE.png', width = 400)\n",
    "\n",
    "display(img2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "neuralODE",
   "language": "python",
   "name": "neuralode"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "vscode": {
   "interpreter": {
    "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
